{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was taken from https://github.com/julia-git/webscraping_ny_mta/blob/master/Webscraping.ipynb\n",
    "# This code downloads turnstile data from http://web.mta.info/developers/turnstile.html\n",
    "\n",
    "# Turnstile data has been compiled by New York MTA every week since May 2010 to the present\n",
    "# So hundreds of .txt files exist on this site. \n",
    "# After visiting the site, you can see it would be a giant pain in the butt to download each of these links manually\n",
    "\n",
    "# This is where code from Python can shine - all of these datasets can be downloaded automatically\n",
    "# Be careful of legal issues and issues with the API however. \n",
    "# Downloading data too rapidly may cause you to be blocked from the site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing the necessary packages\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the URL you want to webscrape from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we set the url to the website\n",
    "url = 'http://web.mta.info/developers/turnstile.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we attempt to access the site with our requests library\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response #200 means it went through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse HTML and save to BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we clean the data a bit with the BeautifulSoup library create a nicer data structure.\n",
    "# BeautifulSoup has good documentation if you are interested\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To locate all  'a' tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since an <a> tag is used to link to the datasets, we can use that to find the locations of\n",
    "# of all of the links on the MTA web page. \n",
    "soup.findAll('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a quick look at the very first data file, which starts on line 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_a_tag = soup.findAll('a')[36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to extract the actual link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = one_a_tag['href']\n",
    "link\n",
    "\n",
    "# This code saves the link to turnstyle data as our variable  link. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full download URL is 'http://web.mta.info/developers/' + link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To download the whole data set, let's do a for loop through all a tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll also notice that we put time.sleep() in this code. This helps us stay on the \n",
    "# API's good side. \n",
    "line_count = 1\n",
    "for one_a_tag in soup.findAll('a'): #'a' tags are for links\n",
    "    if line_count >= 36 and line_count <= 38: #code for text files starts at line 36 and I'm stopping it at 50 because I don't actually want all this data\n",
    "        link = one_a_tag['href']\n",
    "        download_url = 'http://web.mta.info/developers/'+ link\n",
    "        urllib.request.urlretrieve(download_url,'./'+link[link.find('/turnstile_')+1:]) \n",
    "        time.sleep(1)\n",
    "    line_count +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
